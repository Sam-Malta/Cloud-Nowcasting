{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install Deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install keras\n",
        "# !pip install numpy\n",
        "# !pip install tensorflow-gpu==2.10.0\n",
        "# !pip install imageio\n",
        "# !pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from Seq2Seq import Seq2Seq\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from tensorflow import keras\n",
        "import io\n",
        "import imageio\n",
        "from ipywidgets import widgets, HBox\n",
        "\n",
        "from tqdm import tqdm\n",
        "# Use GPU if available\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path = keras.utils.get_file(\n",
        "    \"moving_mnist.npy\",\n",
        "    \"http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy\",\n",
        ")\n",
        "dataset = np.load(data_path).transpose(1, 0, 2, 3)\n",
        "                \n",
        "# Shuffle\n",
        "\n",
        "np.random.shuffle(dataset)\n",
        "\n",
        "train_data = dataset[:8000]\n",
        "test_data = dataset[8000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def collate(batch):\n",
        "\n",
        "    # Add channel dim, scale pixels between 0 and 1, send to GPU\n",
        "    batch = torch.tensor(batch).unsqueeze(1)     \n",
        "    batch = batch / 255.0                        \n",
        "    batch = batch.to(device)                     \n",
        "\n",
        "    # Randomly pick 10 frames as input, 11th frame is target\n",
        "    rand = np.random.randint(10,20)                     \n",
        "    return batch[:,:,rand-10:rand], batch[:,:,rand]     \n",
        "\n",
        "\n",
        "# Training Data Loader\n",
        "train_loader = DataLoader(train_data, shuffle=True, \n",
        "                        batch_size=16, collate_fn=collate)\n",
        "\n",
        "# Validation Data Loader\n",
        "test_loader = DataLoader(test_data, shuffle=True, \n",
        "                        batch_size=16, collate_fn=collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a batch\n",
        "input, _ = next(iter(test_loader))\n",
        "\n",
        "# Reverse process before displaying\n",
        "input = input.cpu().numpy() * 255.0     \n",
        "\n",
        "for video in input.squeeze(1)[:3]:          # Loop over videos\n",
        "    with io.BytesIO() as gif:\n",
        "        imageio.mimsave(gif,video.astype(np.uint8),\"GIF\",fps=5)\n",
        "        display(HBox([widgets.Image(value=gif.getvalue())]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The input video frames are grayscale, thus single channel\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "model = Seq2Seq(num_channels=1, num_kernels=64, \n",
        "kernel_size=(3, 3), padding=(1, 1), activation=\"relu\", \n",
        "frame_size=(255, 255), num_layers=3).to(device)\n",
        "\n",
        "optim = Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Binary Cross Entropy, target pixel values either 0 or 1\n",
        "criterion = nn.BCELoss(reduction='sum')\n",
        "scheduler = StepLR(optim, step_size=10, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "patience = 7\n",
        "best_val_loss = float(\"inf\")\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    \n",
        "    train_loss = 0                                                 \n",
        "    model.train()                                                  \n",
        "    for input, target in tqdm(train_loader):  \n",
        "        output = model(input)                                     \n",
        "        loss = criterion(output.flatten(), target.flatten())       \n",
        "        loss.backward()                                            \n",
        "        optim.step()                                               \n",
        "        optim.zero_grad()                                           \n",
        "        train_loss += loss.item()                                 \n",
        "    train_loss /= len(train_loader)                      \n",
        "\n",
        "    val_loss = 0                                                 \n",
        "    model.eval()                                                  \n",
        "    with torch.no_grad():                                          \n",
        "        for input, target in test_loader:                          \n",
        "            output = model(input)                                   \n",
        "            loss = criterion(output.flatten(), target.flatten())   \n",
        "            val_loss += loss.item()                                \n",
        "    val_loss /= len(test_loader)                           \n",
        "    scheduler.step()\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "        epochs_without_improvement = 0\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "\n",
        "    # If the validation loss hasn't improved for 'patience' epochs, stop training\n",
        "    if epochs_without_improvement == patience:\n",
        "        print('Stopping early')\n",
        "        break\n",
        "\n",
        "    print(\"Epoch:{} Training Loss:{:.2f} Validation Loss:{:.2f}\\n\".format(\n",
        "        epoch, train_loss, val_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_test(batch):\n",
        "\n",
        "    # Last 10 frames are target\n",
        "    target = np.array(batch)[:,10:]                     \n",
        "    \n",
        "    # Add channel dim, scale pixels between 0 and 1, send to GPU\n",
        "    batch = torch.tensor(batch).unsqueeze(1)          \n",
        "    batch = batch / 255.0                             \n",
        "    batch = batch.to(device)                          \n",
        "    return batch, target\n",
        "\n",
        "# Test Data Loader\n",
        "test_loader = DataLoader(test_data,shuffle=True, \n",
        "                         batch_size=10, collate_fn=collate_test)\n",
        "\n",
        "# Get a batch\n",
        "batch, target = next(iter(test_loader))\n",
        "\n",
        "# Initialize output sequence\n",
        "output = np.zeros(target.shape, dtype=np.uint8)\n",
        "\n",
        "# Loop over timesteps\n",
        "for timestep in range(target.shape[1]):\n",
        "  input = batch[:,:,timestep:timestep+10]   \n",
        "  output[:,timestep]=(model(input).squeeze(1).cpu()>0.5)*255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for tgt, out in zip(target, output):       # Loop over samples\n",
        "    \n",
        "    # Write target video as gif\n",
        "    with io.BytesIO() as gif:\n",
        "        imageio.mimsave(gif, tgt, \"GIF\", fps = 5)    \n",
        "        target_gif = gif.getvalue()\n",
        "\n",
        "    # Write output video as gif\n",
        "    with io.BytesIO() as gif:\n",
        "        imageio.mimsave(gif, out, \"GIF\", fps = 5)    \n",
        "        output_gif = gif.getvalue()\n",
        "\n",
        "    display(HBox([widgets.Image(value=target_gif), \n",
        "                  widgets.Image(value=output_gif)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"c_model2.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state_dict = torch.load('model2.pt')\n",
        "\n",
        "# Update the model's state dictionary\n",
        "model.load_state_dict(state_dict)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "conv_lstm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
